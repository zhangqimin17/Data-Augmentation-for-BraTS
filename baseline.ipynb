{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet trained with baseline data\n",
    "\n",
    "## Qimin Zhang and Weiwei Qi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use TorchIO for your research, please cite the following paper:\n",
      "\n",
      "Pérez-García et al., TorchIO: a Python library for efficient loading,\n",
      "preprocessing, augmentation and patch-based sampling of medical images\n",
      "in deep learning\n",
      "(https://arxiv.org/abs/2003.04696)\n",
      "TorchIO version: 0.14.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import enum\n",
    "from time import time\n",
    "import random\n",
    "import warnings\n",
    "import tempfile\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from unet import U_Net\n",
    "\n",
    "from glob import glob\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torchio\n",
    "from torchio import AFFINE, DATA, PATH, TYPE, STEM\n",
    "\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from scipy import stats\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print('TorchIO version:', torchio.__version__)\n",
    "\n",
    "training_split_ratio = 0.9\n",
    "num_epochs = 5\n",
    "compute_histograms = False\n",
    "train_whole_images = False\n",
    "train_patches = False\n",
    "\n",
    "seed = 4460\n",
    "torch.manual_seed(4460)\n",
    "np.random.seed(4460)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation Details\n",
      "\tDevice Used: (cuda)  Tesla K80\n",
      "\n",
      "Packages Used Versions:-\n",
      "\tPytorch Version: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Computation Details')\n",
    "print(f'\\tDevice Used: ({device})  {torch.cuda.get_device_name(torch.cuda.current_device())}\\n')\n",
    "\n",
    "print('Packages Used Versions:-')\n",
    "print(f'\\tPytorch Version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a U-Net with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset folder used\n",
    "DATASET_PATH = os.path.join('./data')\n",
    "\n",
    "# We would like to perform a train-validation-test split at the ratio of T:V:T = 8:1:1.\n",
    "VAL_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "\n",
    "# Batch size for training. Limited by GPU memory\n",
    "BATCH_SIZE = 6\n",
    "# Training Epochs\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/all_gbm_pre_reg/BraTS19_2013_0_1_t1reg.nii.gz\n",
      "./data/all_tumors_reg/BraTS19_2013_0_1_seg_reg.nii.gz\n"
     ]
    }
   ],
   "source": [
    "print(sorted(glob(\"./data/all_gbm_pre_reg/*_t1reg.nii.gz\"))[0])\n",
    "print(sorted(glob(\"./data/all_tumors_reg/*_seg_reg.nii.gz\"))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorDataset(Dataset):\n",
    "    '''\n",
    "    Returns a TumorDataset class object which represents our tumor dataset.\n",
    "    TumorDataset inherits from torch.utils.data.Dataset class.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, root_dir, DEBUG = False):\n",
    "        '''\n",
    "        Constructor for our TumorDataset class.\n",
    "        Parameters:\n",
    "            root_dir(str): Directory with all the images.\n",
    "            DEBUG(bool): To switch to debug mode for image transformation.\n",
    "\n",
    "        Returns: None\n",
    "        '''\n",
    "        self.root_dir = root_dir\n",
    "        # The default transformation is composed of \n",
    "        # 1) a grayscale conversion.\n",
    "        self.default_transformation = transforms.Compose([\n",
    "            transforms.Grayscale()\n",
    "        ])\n",
    "        self.DEBUG = DEBUG\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        Overridden method from inheritted class to support\n",
    "        indexing of dataset such that datset[I] can be used\n",
    "        to get Ith sample.\n",
    "        Parameters:\n",
    "            index(int): Index of the dataset sample\n",
    "            \n",
    "        Return:\n",
    "            sample(dict): Contains the index, image, mask torch.Tensor.\n",
    "                        'index': Index of the image.\n",
    "                        'image': Contains the tumor image torch.Tensor.\n",
    "                        'mask' : Contains the mask image torch.Tensor.\n",
    "        '''\n",
    "        # Find the filenames for the tumor images and masks.\n",
    "        image_path = os.path.join(self.root_dir, \"all_gbm_pre_reg\")\n",
    "        tumor_path = os.path.join(self.root_dir, \"all_tumors_reg\")\n",
    "        \n",
    "        image_name = sorted(glob(os.path.join(image_path, \"*t1reg.nii.gz\")))[index]\n",
    "        mask_name = sorted(glob(os.path.join(tumor_path, \"*seg_reg.nii.gz\")))[index]\n",
    "\n",
    "        # Use nibabel to open the images and masks.\n",
    "        image = nib.load(image_name).get_fdata()\n",
    "        mask = nib.load(mask_name).get_fdata()\n",
    "\n",
    "        # Apply the default transformations on the images and masks.\n",
    "        #image = self.default_transformation(image)\n",
    "        #mask = self.default_transformation(mask)\n",
    "\n",
    "        # Convert the images and masks to tensor.\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "        \n",
    "        # Construct the images and masks together in the form of a dictionary.\n",
    "        sample = {'index': index, 'image': image, 'mask': mask}\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Overridden method from inheritted class so that\n",
    "        len(self) returns the size of the dataset.\n",
    "        '''\n",
    "        error_msg = 'Part of dataset is missing!\\nNumber of tumor and mask images are not same.'\n",
    "        total_image_files = len(glob(os.path.join(self.root_dir, 'all_gbm_pre_reg', '*t1reg.nii.gz')))\n",
    "        total_tumor_files = len(glob(os.path.join(self.root_dir, 'all_tumors_reg', '*seg_reg.nii.gz')))\n",
    "\n",
    "        # Sanity check: the number of files shall be even since tumor images and masks are in pairs.\n",
    "        assert total_image_files == total_tumor_files, error_msg\n",
    "        \n",
    "        # Return how many image-mask pairs we have.\n",
    "        return total_image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(length, val_split, test_split):\n",
    "    '''\n",
    "    Gets the Training & Testing data indices for the dataset.\n",
    "    Stores the indices and returns them back when the same dataset is used.\n",
    "    Inputs:\n",
    "        length(int): Length of the dataset used.\n",
    "        val_split: the portion (0 to 1) of data used for validation.\n",
    "        test_split: the portion (0 to 1) of data used for testing.\n",
    "    Parameters:\n",
    "        train_indices(list): Array of indices used for training purpose.\n",
    "        validation_indices(list): Array of indices used for validation purpose.\n",
    "        test_indices(list): Array of indices used for testing purpose.\n",
    "    '''\n",
    "    data = dict()\n",
    "    indices = list(range(length))\n",
    "    np.random.shuffle(indices)\n",
    "    split1 = int(np.floor(test_split * len(tumor_dataset)))\n",
    "    split2 = split1 + int(np.floor(val_split * len(tumor_dataset)))\n",
    "    train_indices, validation_indices, test_indices = indices[split2:], indices[split1:split2], indices[:split1]\n",
    "    return train_indices, validation_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the train set: 269 \n",
      "Number of files in the validation set: 33 \n",
      "Number of files in the test set: 33\n"
     ]
    }
   ],
   "source": [
    "tumor_dataset = TumorDataset(DATASET_PATH)\n",
    "\n",
    "train_indices, validation_indices, test_indices = get_indices(len(tumor_dataset), val_split = VAL_SPLIT, test_split = TEST_SPLIT)\n",
    "train_sampler, validation_sampler, test_sampler = SubsetRandomSampler(train_indices), SubsetRandomSampler(validation_indices), SubsetRandomSampler(test_indices)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(tumor_dataset, BATCH_SIZE, sampler = train_sampler)\n",
    "validationloader = torch.utils.data.DataLoader(tumor_dataset, 1, sampler = validation_sampler)\n",
    "testloader = torch.utils.data.DataLoader(tumor_dataset, 1, sampler = test_sampler)\n",
    "\n",
    "print('Number of files in the train set: %s \\nNumber of files in the validation set: %s \\nNumber of files in the test set: %s' \\\n",
    "      % (len(train_indices), len(validation_indices), len(test_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([155, 240, 240])\n",
      "torch.Size([155, 240, 240])\n"
     ]
    }
   ],
   "source": [
    "print(tumor_dataset.__getitem__(0)['image'].size())\n",
    "print(tumor_dataset.__getitem__(0)['mask'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(predicted, target):\n",
    "    '''\n",
    "    Calculates the Sørensen–Dice Coefficient for a single sample.\n",
    "    Parameters:\n",
    "        predicted(numpy.ndarray): Predicted single output of the network.\n",
    "                                Shape - (Channel, Height, Width)\n",
    "        target(numpy.ndarray): Actual required single output for the network\n",
    "                                Shape - (Channel, Height, Width)\n",
    "\n",
    "    Returns:\n",
    "        coefficient(float): Dice coefficient for the input sample.\n",
    "                                    1 represents highest similarity and\n",
    "                                    0 represents lowest similarity.\n",
    "    '''\n",
    "    # The smooth term is used to prevent division by zero.\n",
    "    smooth = 1\n",
    "    product = np.multiply(predicted, target)\n",
    "    intersection = np.sum(product)\n",
    "    coefficient = (2 * intersection + smooth) / (np.sum(predicted) + np.sum(target) + smooth)\n",
    "    return coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 11.17 GiB total capacity; 72.13 MiB already allocated; 17.06 MiB free; 76.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bffd10b727d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# New model is created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0munet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU_Net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#### You can uncomment this to see the textual architecture of our U-Net.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BMEN4460/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BMEN4460/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BMEN4460/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BMEN4460/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BMEN4460/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BMEN4460/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 11.17 GiB total capacity; 72.13 MiB already allocated; 17.06 MiB free; 76.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "unet_classifier = None\n",
    "criterion = nn.BCELoss()\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#### If you want to see the training trend within each epoch, you can change mini_batch to a positive integer \n",
    "#### that is no larger than the number of batches per epoch.\n",
    "mini_batch = False\n",
    "\n",
    "# Define where to save the model parameters.\n",
    "model_save_path = './baseline_saved_models/'\n",
    "os.makedirs(model_save_path, exist_ok = True)\n",
    "\n",
    "# New model is created.\n",
    "unet_model = U_Net().to(device)\n",
    "\n",
    "#### You can uncomment this to see the textual architecture of our U-Net.\n",
    "#print(unet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Process\n",
      "Epoch:   1,  train Loss: 0.10727,  validation Loss: 0.34370,  validation score: 0.06426,  current lr:  0.0001 , Time: 496.89 s\tBest model saved at score: 0.06426\n",
      "Epoch:   2,  train Loss: 0.02477,  validation Loss: 0.08035,  validation score: 0.01116,  current lr:  0.0001 , Time: 370.14 s\n",
      "Epoch:   3,  train Loss: 0.01381,  validation Loss: 0.06753,  validation score: 0.00034,  current lr:  0.0001 , Time: 369.54 s\n",
      "Epoch:   4,  train Loss: 0.01178,  validation Loss: 0.06270,  validation score: 0.00193,  current lr:  0.0001 , Time: 368.39 s\n",
      "Epoch:   5,  train Loss: 0.01104,  validation Loss: 0.05989,  validation score: 0.00029,  current lr:  0.0001 , Time: 367.62 s\n",
      "Epoch:   6,  train Loss: 0.01079,  validation Loss: 0.06018,  validation score: 0.00001,  current lr:  0.0001 , Time: 368.43 s\n",
      "Epoch:   7,  train Loss: 0.01070,  validation Loss: 0.05826,  validation score: 0.00030,  current lr:  0.0001 , Time: 368.56 s\n",
      "Epoch:   8,  train Loss: 0.01050,  validation Loss: 0.05924,  validation score: 0.00835,  current lr:  0.0001 , Time: 368.52 s\n",
      "Epoch:   9,  train Loss: 0.01055,  validation Loss: 0.05914,  validation score: 0.00853,  current lr:  0.0001 , Time: 368.12 s\n",
      "Epoch:  10,  train Loss: 0.01037,  validation Loss: 0.05712,  validation score: 0.03081,  current lr:  0.0001 , Time: 368.19 s\n",
      "Epoch:  11,  train Loss: 0.01097,  validation Loss: 0.05813,  validation score: 0.01365,  current lr:  0.0001 , Time: 368.41 s\n",
      "Epoch:  12,  train Loss: 0.01053,  validation Loss: 0.05673,  validation score: 0.04424,  current lr:  0.0001 , Time: 368.93 s\n",
      "Epoch:  13,  train Loss: 0.01019,  validation Loss: 0.05822,  validation score: 0.01371,  current lr:  0.0001 , Time: 368.72 s\n",
      "Epoch:  14,  train Loss: 0.01014,  validation Loss: 0.05730,  validation score: 0.04700,  current lr:  0.0001 , Time: 368.25 s\n",
      "Epoch    15: reducing learning rate of group 0 to 8.5000e-05.\n",
      "Epoch:  15,  train Loss: 0.00995,  validation Loss: 0.05817,  validation score: 0.02786,  current lr:  8.5e-05 , Time: 367.91 s\n",
      "Epoch:  16,  train Loss: 0.00992,  validation Loss: 0.05440,  validation score: 0.06559,  current lr:  8.5e-05 , Time: 367.72 s\tBest model saved at score: 0.06559\n",
      "Epoch:  17,  train Loss: 0.00986,  validation Loss: 0.05533,  validation score: 0.09313,  current lr:  8.5e-05 , Time: 368.61 s\tBest model saved at score: 0.09313\n",
      "Epoch:  18,  train Loss: 0.00968,  validation Loss: 0.05378,  validation score: 0.03315,  current lr:  8.5e-05 , Time: 367.92 s\n",
      "Epoch:  19,  train Loss: 0.00943,  validation Loss: 0.05220,  validation score: 0.11844,  current lr:  8.5e-05 , Time: 368.58 s\tBest model saved at score: 0.11844\n",
      "Epoch:  20,  train Loss: 0.00966,  validation Loss: 0.05471,  validation score: 0.10671,  current lr:  8.5e-05 , Time: 369.73 s\n",
      "Epoch:  21,  train Loss: 0.00936,  validation Loss: 0.05101,  validation score: 0.08525,  current lr:  8.5e-05 , Time: 367.19 s\n",
      "Epoch:  22,  train Loss: 0.00915,  validation Loss: 0.04847,  validation score: 0.18663,  current lr:  8.5e-05 , Time: 367.14 s\tBest model saved at score: 0.18663\n",
      "Epoch:  23,  train Loss: 0.00863,  validation Loss: 0.04924,  validation score: 0.20156,  current lr:  8.5e-05 , Time: 367.98 s\tBest model saved at score: 0.20156\n",
      "Epoch:  24,  train Loss: 0.00889,  validation Loss: 0.05150,  validation score: 0.09286,  current lr:  8.5e-05 , Time: 368.17 s\n",
      "Epoch:  25,  train Loss: 0.00895,  validation Loss: 0.04483,  validation score: 0.12365,  current lr:  8.5e-05 , Time: 367.97 s\n",
      "Epoch:  26,  train Loss: 0.00832,  validation Loss: 0.04558,  validation score: 0.21467,  current lr:  8.5e-05 , Time: 368.94 s\tBest model saved at score: 0.21467\n",
      "Epoch:  27,  train Loss: 0.00789,  validation Loss: 0.04220,  validation score: 0.27131,  current lr:  8.5e-05 , Time: 369.14 s\tBest model saved at score: 0.27131\n",
      "Epoch:  28,  train Loss: 0.00764,  validation Loss: 0.04078,  validation score: 0.29748,  current lr:  8.5e-05 , Time: 368.42 s\tBest model saved at score: 0.29748\n",
      "Epoch:  29,  train Loss: 0.00787,  validation Loss: 0.04583,  validation score: 0.35271,  current lr:  8.5e-05 , Time: 368.74 s\tBest model saved at score: 0.35271\n",
      "Epoch:  30,  train Loss: 0.00686,  validation Loss: 0.04718,  validation score: 0.38310,  current lr:  8.5e-05 , Time: 368.26 s\tBest model saved at score: 0.38310\n",
      "Epoch    31: reducing learning rate of group 0 to 7.2250e-05.\n",
      "Epoch:  31,  train Loss: 0.00700,  validation Loss: 0.04198,  validation score: 0.38041,  current lr:  7.225000000000001e-05 , Time: 368.84 s\n",
      "Epoch:  32,  train Loss: 0.00608,  validation Loss: 0.03768,  validation score: 0.42081,  current lr:  7.225000000000001e-05 , Time: 369.03 s\tBest model saved at score: 0.42081\n",
      "Epoch:  33,  train Loss: 0.00608,  validation Loss: 0.04817,  validation score: 0.49178,  current lr:  7.225000000000001e-05 , Time: 368.82 s\tBest model saved at score: 0.49178\n",
      "Epoch:  34,  train Loss: 0.00537,  validation Loss: 0.05259,  validation score: 0.19959,  current lr:  7.225000000000001e-05 , Time: 368.25 s\n",
      "Epoch    35: reducing learning rate of group 0 to 6.1413e-05.\n",
      "Epoch:  35,  train Loss: 0.00679,  validation Loss: 0.08758,  validation score: 0.34146,  current lr:  6.141250000000001e-05 , Time: 369.55 s\n",
      "Epoch:  36,  train Loss: 0.00390,  validation Loss: 0.05058,  validation score: 0.40149,  current lr:  6.141250000000001e-05 , Time: 369.73 s\n",
      "Epoch:  37,  train Loss: 0.00065,  validation Loss: 0.03112,  validation score: 0.41122,  current lr:  6.141250000000001e-05 , Time: 369.59 s\n",
      "Epoch:  38,  train Loss: -0.00084,  validation Loss: 0.03334,  validation score: 0.49053,  current lr:  6.141250000000001e-05 , Time: 369.60 s\n",
      "Epoch:  39,  train Loss: -0.00497,  validation Loss: 0.01365,  validation score: 0.53908,  current lr:  6.141250000000001e-05 , Time: 368.98 s\tBest model saved at score: 0.53908\n",
      "Epoch:  40,  train Loss: -0.00649,  validation Loss: -0.00639,  validation score: 0.49897,  current lr:  6.141250000000001e-05 , Time: 369.70 s\n",
      "Epoch:  41,  train Loss: -0.00776,  validation Loss: 0.00897,  validation score: 0.52402,  current lr:  6.141250000000001e-05 , Time: 368.09 s\n",
      "Epoch:  42,  train Loss: -0.00873,  validation Loss: 0.00014,  validation score: 0.62189,  current lr:  6.141250000000001e-05 , Time: 367.96 s\tBest model saved at score: 0.62189\n",
      "Epoch    43: reducing learning rate of group 0 to 5.2201e-05.\n",
      "Epoch:  43,  train Loss: -0.01050,  validation Loss: 0.01847,  validation score: 0.56278,  current lr:  5.2200625000000005e-05 , Time: 367.59 s\n",
      "Epoch:  44,  train Loss: -0.01188,  validation Loss: -0.00675,  validation score: 0.58549,  current lr:  5.2200625000000005e-05 , Time: 367.79 s\n",
      "Epoch:  45,  train Loss: -0.01145,  validation Loss: -0.00058,  validation score: 0.55268,  current lr:  5.2200625000000005e-05 , Time: 369.15 s\n",
      "Epoch:  46,  train Loss: -0.01357,  validation Loss: 0.00344,  validation score: 0.59092,  current lr:  5.2200625000000005e-05 , Time: 368.21 s\n",
      "Epoch    47: reducing learning rate of group 0 to 4.4371e-05.\n",
      "Epoch:  47,  train Loss: -0.01534,  validation Loss: 0.01137,  validation score: 0.58007,  current lr:  4.437053125e-05 , Time: 368.05 s\n",
      "Epoch:  48,  train Loss: -0.01447,  validation Loss: 0.00211,  validation score: 0.60739,  current lr:  4.437053125e-05 , Time: 368.03 s\n",
      "Epoch:  49,  train Loss: -0.01619,  validation Loss: -0.00446,  validation score: 0.53888,  current lr:  4.437053125e-05 , Time: 368.25 s\n",
      "Epoch    50: reducing learning rate of group 0 to 3.7715e-05.\n",
      "Epoch:  50,  train Loss: -0.01683,  validation Loss: -0.00419,  validation score: 0.60964,  current lr:  3.77149515625e-05 , Time: 368.98 s\n",
      "Epoch:  51,  train Loss: -0.01708,  validation Loss: 0.00698,  validation score: 0.57928,  current lr:  3.77149515625e-05 , Time: 367.70 s\n",
      "Epoch:  52,  train Loss: -0.01830,  validation Loss: 0.00579,  validation score: 0.58452,  current lr:  3.77149515625e-05 , Time: 367.47 s\n",
      "Epoch:  53,  train Loss: -0.01896,  validation Loss: -0.01704,  validation score: 0.61336,  current lr:  3.77149515625e-05 , Time: 368.07 s\n",
      "Epoch:  54,  train Loss: -0.01962,  validation Loss: -0.00904,  validation score: 0.63323,  current lr:  3.77149515625e-05 , Time: 367.94 s\tBest model saved at score: 0.63323\n",
      "Epoch:  55,  train Loss: -0.01944,  validation Loss: -0.01736,  validation score: 0.60565,  current lr:  3.77149515625e-05 , Time: 369.89 s\n",
      "Epoch:  56,  train Loss: -0.01993,  validation Loss: -0.00043,  validation score: 0.60873,  current lr:  3.77149515625e-05 , Time: 368.82 s\n",
      "Epoch:  57,  train Loss: -0.02064,  validation Loss: -0.00901,  validation score: 0.60357,  current lr:  3.77149515625e-05 , Time: 368.22 s\n",
      "Epoch    58: reducing learning rate of group 0 to 3.2058e-05.\n",
      "Epoch:  58,  train Loss: -0.02150,  validation Loss: -0.01311,  validation score: 0.59718,  current lr:  3.2057708828124995e-05 , Time: 368.10 s\n",
      "Epoch:  59,  train Loss: -0.02151,  validation Loss: -0.01807,  validation score: 0.63244,  current lr:  3.2057708828124995e-05 , Time: 367.99 s\n",
      "Epoch:  60,  train Loss: -0.02231,  validation Loss: -0.00299,  validation score: 0.62665,  current lr:  3.2057708828124995e-05 , Time: 367.15 s\n",
      "Epoch:  61,  train Loss: -0.02292,  validation Loss: -0.00044,  validation score: 0.60491,  current lr:  3.2057708828124995e-05 , Time: 367.40 s\n",
      "Epoch    62: reducing learning rate of group 0 to 2.7249e-05.\n",
      "Epoch:  62,  train Loss: -0.02342,  validation Loss: -0.00944,  validation score: 0.61388,  current lr:  2.7249052503906245e-05 , Time: 367.50 s\n",
      "Epoch:  63,  train Loss: -0.02387,  validation Loss: -0.01306,  validation score: 0.64965,  current lr:  2.7249052503906245e-05 , Time: 367.30 s\tBest model saved at score: 0.64965\n",
      "Epoch:  64,  train Loss: -0.02449,  validation Loss: -0.01220,  validation score: 0.61880,  current lr:  2.7249052503906245e-05 , Time: 367.20 s\n",
      "Epoch    65: reducing learning rate of group 0 to 2.3162e-05.\n",
      "Epoch:  65,  train Loss: -0.02464,  validation Loss: -0.00577,  validation score: 0.60855,  current lr:  2.3161694628320308e-05 , Time: 367.45 s\n",
      "Epoch:  66,  train Loss: -0.02499,  validation Loss: -0.01528,  validation score: 0.61646,  current lr:  2.3161694628320308e-05 , Time: 367.70 s\n",
      "Epoch:  67,  train Loss: -0.02546,  validation Loss: -0.00778,  validation score: 0.62748,  current lr:  2.3161694628320308e-05 , Time: 367.48 s\n",
      "Epoch    68: reducing learning rate of group 0 to 1.9687e-05.\n",
      "Epoch:  68,  train Loss: -0.02542,  validation Loss: -0.00946,  validation score: 0.63902,  current lr:  1.9687440434072263e-05 , Time: 367.57 s\n",
      "Epoch:  69,  train Loss: -0.02589,  validation Loss: -0.01184,  validation score: 0.65553,  current lr:  1.9687440434072263e-05 , Time: 368.09 s\tBest model saved at score: 0.65553\n",
      "Epoch:  70,  train Loss: -0.02644,  validation Loss: -0.01639,  validation score: 0.62513,  current lr:  1.9687440434072263e-05 , Time: 368.76 s\n",
      "Epoch    71: reducing learning rate of group 0 to 1.6734e-05.\n",
      "Epoch:  71,  train Loss: -0.02653,  validation Loss: -0.01034,  validation score: 0.65080,  current lr:  1.673432436896142e-05 , Time: 369.02 s\n",
      "Epoch:  72,  train Loss: -0.02674,  validation Loss: -0.01672,  validation score: 0.64525,  current lr:  1.673432436896142e-05 , Time: 369.20 s\n",
      "Epoch:  73,  train Loss: -0.02695,  validation Loss: -0.00818,  validation score: 0.63856,  current lr:  1.673432436896142e-05 , Time: 369.09 s\n"
     ]
    }
   ],
   "source": [
    "# Training session history data.\n",
    "history = {'train_loss': list(), 'validation_loss': list()}\n",
    "\n",
    "# For save best feature. Initial loss taken a very high value.\n",
    "last_score = 0\n",
    "\n",
    "# Optimizer used for training process. Adam Optimizer.\n",
    "optimizer = optim.Adam(unet_model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Reducing LR on plateau feature to improve training.\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.85, patience = 2, verbose = True)\n",
    "\n",
    "print('Starting Training Process')\n",
    "\n",
    "assert validationloader.batch_size == 1\n",
    "\n",
    "# Epoch Loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #################################### Train ####################################################\n",
    "    unet_model.train()\n",
    "    start_time = time()\n",
    "    # Training a single epoch\n",
    "    train_epoch_loss, train_batch_loss, batch_iteration = 0, 0, 0\n",
    "    validation_score, validation_loss = 0, 0\n",
    "\n",
    "    for batch, data in enumerate(trainloader):\n",
    "        # Keeping track how many iteration is happening.\n",
    "        batch_iteration += 1\n",
    "        # Loading data to device used.\n",
    "        image = data['image'].to(device, dtype=torch.float)\n",
    "        mask = data['mask'].to(device, dtype=torch.float)\n",
    "        # Clearing gradients of optimizer.\n",
    "        optimizer.zero_grad()\n",
    "        # Calculation predicted output using forward pass.\n",
    "        output = unet_model(image)\n",
    "        # Calculating the loss value.\n",
    "        loss_value = criterion(output, mask)\n",
    "        # Computing the gradients.\n",
    "        loss_value.backward()\n",
    "        # Optimizing the network parameters.\n",
    "        optimizer.step()\n",
    "        # Updating the running training loss\n",
    "        train_epoch_loss += loss_value.item()\n",
    "        train_batch_loss += loss_value.item()\n",
    "\n",
    "        # Printing batch logs if any. Useful if you want to see the training trends within each epoch.\n",
    "        if mini_batch:\n",
    "            if (batch + 1) % mini_batch == 0:\n",
    "                train_batch_loss = train_batch_loss / (mini_batch * trainloader.batch_size)\n",
    "                print(\n",
    "                    f'    Batch: {batch + 1:2d},\\tBatch Loss: {train_batch_loss:.7f}')\n",
    "                train_batch_loss = 0\n",
    "\n",
    "    train_epoch_loss = train_epoch_loss / (batch_iteration * trainloader.batch_size)\n",
    "    \n",
    "    ################################### Validation ##################################################\n",
    "    unet_model.eval()\n",
    "    # To get data in loops.\n",
    "    batch_iteration = 0\n",
    "\n",
    "    for batch, data in enumerate(validationloader):\n",
    "        # Keeping track how many iteration is happening.\n",
    "        batch_iteration += 1\n",
    "        # Data prepared to be given as input to model.\n",
    "        image = data['image'].to(device, dtype=torch.float)\n",
    "        mask = data['mask'].to(device, dtype=torch.float)\n",
    "\n",
    "        # Predicted output from the input sample.\n",
    "        mask_prediction = unet_model(image)\n",
    "        \n",
    "        # comput validation loss\n",
    "        loss_value = criterion(mask_prediction, mask)\n",
    "        validation_loss += loss_value.item()\n",
    "        \n",
    "        # Threshold elimination.\n",
    "        mask_prediction = (mask_prediction > 0.5)\n",
    "        mask_prediction = mask_prediction.cpu().numpy()\n",
    "        mask = mask.cpu().numpy()\n",
    "\n",
    "        mask = np.resize(mask, (155, 240, 240))\n",
    "        mask_prediction = np.resize(mask_prediction, (155, 240, 240))\n",
    "        # Calculate the dice score for original and predicted image mask.\n",
    "        validation_score += dice_coefficient(mask_prediction, mask)\n",
    "\n",
    "    # Calculating the mean score for the whole validation dataset.\n",
    "    unet_val = validation_score / batch_iteration\n",
    "    validation_loss = validation_loss / batch_iteration\n",
    "    \n",
    "    # Collecting all epoch loss values for future visualization.\n",
    "    history['train_loss'].append(train_epoch_loss)\n",
    "    history['validation_loss'].append(validation_loss)\n",
    "    \n",
    "    # Reduce LR On Plateau\n",
    "    scheduler.step(validation_loss)\n",
    "\n",
    "    time_taken = time() - start_time\n",
    "    \n",
    "    # Training Logs printed.\n",
    "    print(f'Epoch: {epoch + 1:3d},  ', end = '')\n",
    "    print(f'train Loss: {train_epoch_loss:.5f},  ', end = '')\n",
    "    print(f'validation Loss: {validation_loss:.5f},  ', end = '')\n",
    "    print(f'validation score: {unet_val:.5f},  ', end = '')\n",
    "\n",
    "    for pg in optimizer.param_groups:\n",
    "        print('current lr: ', pg['lr'], ', ', end = '')\n",
    "    print(f'Time: {time_taken:.2f} s', end = '')\n",
    "\n",
    "    # Save the model every epoch.\n",
    "    #current_epoch_model_save_path = os.path.join(model_save_path, 'Basic_Unet_epoch_%s.pth' % (str(epoch).zfill(3)))\n",
    "    #torch.save(unet_model.state_dict(), current_epoch_model_save_path)\n",
    "    \n",
    "    # Save the best model (determined by validation score) and give it a unique name.\n",
    "    best_model_path = os.path.join(model_save_path, 'Basic_Unet_best_model.pth')\n",
    "    if  last_score < unet_val:\n",
    "        torch.save(unet_model.state_dict(), best_model_path)\n",
    "        last_score = unet_val\n",
    "        print(f'\\tBest model saved at score: {unet_val:.5f}')\n",
    "    else:\n",
    "        print()\n",
    "\n",
    "print(f'Training Finished after {epochs} epoches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title('Loss Over Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss Value')\n",
    "train_curve = plt.plot(history['train_loss'], marker = 'o', label = 'Train loss')\n",
    "validation_curve = plt.plot(history['validation_loss'], marker = 'o', label = 'Validation loss')\n",
    "plt.legend(fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.17 GiB total capacity; 74.50 MiB already allocated; 15.06 MiB free; 78.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-346bebb72f3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the unet model at its prime (when it performed the best on the validation set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Basic_Unet_best_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0munet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Testing process on test data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BMEN4460/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BMEN4460/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BMEN4460/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    663\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BMEN4460/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BMEN4460/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BMEN4460/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;31m# del _CudaBase.__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.17 GiB total capacity; 74.50 MiB already allocated; 15.06 MiB free; 78.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# Load the unet model at its prime (when it performed the best on the validation set).\n",
    "state_dict = torch.load(os.path.join(model_save_path, 'Basic_Unet_best_model.pth'))\n",
    "unet_model.load_state_dict(state_dict)\n",
    "\n",
    "# Testing process on test data.\n",
    "unet_model.eval()\n",
    "# Getting test data indices for dataloading\n",
    "test_data_indexes = test_indices\n",
    "# Total testing data used.\n",
    "data_length = len(test_data_indexes)\n",
    "# Score after testing on dataset.\n",
    "mean_test_score = 0\n",
    "\n",
    "for batch, data in enumerate(testloader):\n",
    "    # Data prepared to be given as input to model.\n",
    "    image = data['image'].to(device, dtype=torch.float)\n",
    "    mask = data['mask']\n",
    "\n",
    "    # Predicted output from the input sample.\n",
    "    mask_prediction = unet_model(image).cpu()\n",
    "    # Threshold elimination.\n",
    "    mask_prediction = (mask_prediction > 0.5)\n",
    "    mask_prediction = mask_prediction.numpy()\n",
    "\n",
    "    mask = np.resize(mask, (155, 240, 240))\n",
    "    mask_prediction = np.resize(mask_prediction, (155, 240, 240))\n",
    "\n",
    "    # Calculating the dice score for original and predicted mask.\n",
    "    mean_test_score += dice_coefficient(mask_prediction, mask)\n",
    "\n",
    "# Calculating the mean score for the whole test dataset.\n",
    "unet_score = mean_test_score / data_length\n",
    "# Putting the model back to training mode.\n",
    "print(f'\\nDice Score {unet_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(image, mask, output, title, transparency = 0.38, save_path = None):\n",
    "    '''\n",
    "    Plots a 2x3 plot with comparisons of output and original image.\n",
    "    Works best with Jupyter Notebook/Lab.\n",
    "    Parameters:\n",
    "        image(numpy.ndarray): Array containing the original image of MRI scan.\n",
    "        mask(numpy.ndarray): Array containing the original mask of tumor.\n",
    "        output(numpy.ndarray): Model predicted mask from input image.\n",
    "        title(str): Title of the plot to be used.\n",
    "        transparency(float): Transparency level of mask on images.\n",
    "                             Default: 0.38\n",
    "        save_path(str): Saves the plot to the location specified.\n",
    "                        Does nothing if None. \n",
    "                        Default: None\n",
    "    Return:\n",
    "        None\n",
    "    '''\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(\n",
    "        10, 8), gridspec_kw={'wspace': 0.025, 'hspace': 0.010})\n",
    "    fig.suptitle(title, x=0.5, y=0.92, fontsize=20)\n",
    "\n",
    "    axs[0][0].set_title(\"Original Mask\", fontdict={'fontsize': 16})\n",
    "    axs[0][0].imshow(mask, cmap='gray')\n",
    "    axs[0][0].set_axis_off()\n",
    "\n",
    "    axs[0][1].set_title(\"Predicted Mask\", fontdict={'fontsize': 16})\n",
    "    axs[0][1].imshow(output, cmap='gray')\n",
    "    axs[0][1].set_axis_off()\n",
    "\n",
    "    mask_diff = np.abs(np.subtract(mask, output))\n",
    "    axs[0][2].set_title(\"Mask Difference\", fontdict={'fontsize': 16})\n",
    "    axs[0][2].imshow(mask_diff, cmap='gray')\n",
    "    axs[0][2].set_axis_off()\n",
    "\n",
    "    seg_output = mask*transparency\n",
    "    seg_image = np.add(image, seg_output)/2\n",
    "    axs[1][0].set_title(\"Original Segmentation\", fontdict={'fontsize': 16})\n",
    "    axs[1][0].imshow(seg_image, cmap='gray')\n",
    "    axs[1][0].set_axis_off()\n",
    "    \n",
    "    seg_output = output*transparency\n",
    "    seg_image = np.add(image, seg_output)/2\n",
    "    axs[1][1].set_title(\"Predicted Segmentation\", fontdict={'fontsize': 16})\n",
    "    axs[1][1].imshow(seg_image, cmap='gray')\n",
    "    axs[1][1].set_axis_off()\n",
    "\n",
    "    axs[1][2].set_title(\"Original Input Image\", fontdict={'fontsize': 16})\n",
    "    axs[1][2].imshow(image, cmap='gray')\n",
    "    axs[1][2].set_axis_off()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi = 90, bbox_inches = 'tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fd51fdd67c3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# The purpose of image_index is to make sure we truly pick from the test set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtumor_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_indices' is not defined"
     ]
    }
   ],
   "source": [
    "for example_index in range(10):\n",
    "    # The purpose of image_index is to make sure we truly pick from the test set.\n",
    "    image_index = test_indices[example_index]\n",
    "    sample = tumor_dataset[image_index]\n",
    "    threshold = 0.5\n",
    "\n",
    "    unet_model.eval()\n",
    "    image = sample['image'].numpy()\n",
    "    mask = sample['mask'].numpy()\n",
    "\n",
    "    image_tensor = torch.Tensor(image)\n",
    "    image_tensor = image_tensor.view((-1, 155, 240, 240)).to(device)\n",
    "    output = unet_model(image_tensor).detach().cpu()\n",
    "    output = (output > threshold)\n",
    "    output = output.numpy()\n",
    "\n",
    "\n",
    "    image = np.resize(image, (155, 240, 240))\n",
    "    image = image[70,:,:]\n",
    "    mask = np.resize(mask, (155, 240, 240))\n",
    "    mask = mask[70,:,:]\n",
    "    output = np.resize(output, (155, 240, 240))\n",
    "    output = output[70,:,:]\n",
    "    # score(float): Sørensen–Dice Coefficient for mask and output. Calculates how similar are the two images.\n",
    "    d_score = dice_coefficient(output, mask)\n",
    "\n",
    "    title = f'Name: {image_index}.png   Dice Score: {d_score:.5f}'\n",
    "    # save_path = os.path.join('images',f'{d_score:.5f}_{image_index}.png')\n",
    "    result(image, mask, output, title, save_path = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 BMEN4460",
   "language": "python",
   "name": "bmen4460"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
